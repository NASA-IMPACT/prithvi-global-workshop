Learning Rate: 0.0001
Batch Size: 8
Number of Epochs: 125
Number of Input Channel: 6
Number of Segmentation Class: 2
Used device name: cuda
Checkpoint Path: /rhome/rghosal/Rinki/rinki-hls-foundation-os/prithvi_burn_checkpoint/checkpoint_burn_prithvi.pth
Data input dir:/rhome/rghosal/burn_scar/hls_burn_scars/
wandb: Currently logged in as: rinki447 (rinki447-the-university-of-alabama-in-huntsville). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.7
wandb: Run data is saved locally in /nas/rhome/rghosal/Rinki/rinki-hls-foundation-os/prithvi_merra/prithvi_burn/wandb/run-20240902_123813-79uet4pv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-wind-64
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rinki447-the-university-of-alabama-in-huntsville/HLS-burn-finetune-prithviGlobal
wandb: üöÄ View run at https://wandb.ai/rinki447-the-university-of-alabama-in-huntsville/HLS-burn-finetune-prithviGlobal/runs/79uet4pv
checkpoint names: dict_keys(['epoch', 'iter', 'model', 'optimizer', 'scheduler', 'scaler', 'loss', 'best_val_loss', 'steps_per_epoch'])
iteration started
Epoch: 0, train loss: 0.6236985175697892, val loss:0.4627923522934769,accuracy_train:0.6445172185084971,accuracy_val:0.8231388014190051,miou_train:0.39025454179329033,miou_val:0.5135330242269179
Traceback (most recent call last):
  File "/nas/rhome/rghosal/Rinki/rinki-hls-foundation-os/prithvi_merra/prithvi_burn/main_prithvi_burn.py", line 311, in <module>
    main()
  File "/nas/rhome/rghosal/Rinki/rinki-hls-foundation-os/prithvi_merra/prithvi_burn/main_prithvi_burn.py", line 295, in main
    scheduler.step()
TypeError: step() missing 1 required positional argument: 'metrics'
wandb: - 0.166 MB of 0.166 MB uploaded (0.149 MB deduped)wandb: \ 0.180 MB of 0.180 MB uploaded (0.149 MB deduped)wandb: 
wandb: Run history:
wandb:     acc_train ‚ñÅ
wandb:  accuracy_val ‚ñÅ
wandb:         epoch ‚ñÅ‚ñÅ
wandb: learning_rate ‚ñÅ
wandb:    miou_train ‚ñÅ
wandb:      miou_val ‚ñÅ
wandb:    train_loss ‚ñÅ
wandb:      val_loss ‚ñÅ
wandb: 
wandb: Run summary:
wandb:     acc_train 0.64452
wandb:  accuracy_val 0.82314
wandb:         epoch 1
wandb: learning_rate 2e-05
wandb:    miou_train 0.39025
wandb:      miou_val 0.51353
wandb:    train_loss 0.6237
wandb:      val_loss 0.46279
wandb: 
wandb: üöÄ View run hearty-wind-64 at: https://wandb.ai/rinki447-the-university-of-alabama-in-huntsville/HLS-burn-finetune-prithviGlobal/runs/79uet4pv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/rinki447-the-university-of-alabama-in-huntsville/HLS-burn-finetune-prithviGlobal
wandb: Synced 6 W&B file(s), 0 media file(s), 29 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240902_123813-79uet4pv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 120737) of binary: /rhome/rghosal/anaconda3/envs/hls2/bin/python
Traceback (most recent call last):
  File "/rhome/rghosal/anaconda3/envs/hls2/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/rhome/rghosal/anaconda3/envs/hls2/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/rhome/rghosal/anaconda3/envs/hls2/lib/python3.9/site-packages/torch/distributed/run.py", line 724, in main
    run(args)
  File "/rhome/rghosal/anaconda3/envs/hls2/lib/python3.9/site-packages/torch/distributed/run.py", line 715, in run
    elastic_launch(
  File "/rhome/rghosal/anaconda3/envs/hls2/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/rhome/rghosal/anaconda3/envs/hls2/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_prithvi_burn.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-09-02_12:39:30
  host      : matrix101.nsstc.uah.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 120737)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
