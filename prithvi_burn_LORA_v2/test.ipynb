{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_accuracy(labels, output):\n",
    "\n",
    "    \n",
    "    # (batch_size, 2_class,time_frame,224, 224) ->  (batch_size, 224, 224)\n",
    "    #output=output.squeeze(2)\n",
    "    predicted = torch.argmax(output, dim=1)\n",
    "    print(predicted)\n",
    "    # Compare the predicted class with the true labels\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    total = labels.numel()  # Total number of elements in labels\n",
    "    \n",
    "    accuracy = correct / total \n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(labels, output):\n",
    "    # (batch_size, 2_class, time_frame, 224, 224) -> (batch_size, 224, 224)\n",
    "    predicted = torch.argmax(output, dim=1)\n",
    "    \n",
    "    # Flatten the labels and predictions to work with individual elements\n",
    "    predicted = predicted.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "    \n",
    "    # True Positives (TP): Both predicted and true labels are 1\n",
    "    TP = ((predicted == 1) & (labels == 1)).sum().item()\n",
    "    \n",
    "    # True Negatives (TN): Both predicted and true labels are 0\n",
    "    TN = ((predicted == 0) & (labels == 0)).sum().item()\n",
    "    \n",
    "    # False Positives (FP): Predicted is 1, but true label is 0\n",
    "    FP = ((predicted == 1) & (labels == 0)).sum().item()\n",
    "    \n",
    "    # False Negatives (FN): Predicted is 0, but true label is 1\n",
    "    FN = ((predicted == 0) & (labels == 1)).sum().item()\n",
    "    \n",
    "    # Accuracy: (TP + TN) / Total\n",
    "    total = labels.numel()\n",
    "    accuracy = (TP + TN) / total\n",
    "    # Precision: TP / (TP + FP)\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    # Recall: TP / (TP + FN)\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    #miou_1=TP/(TP+FN+FP)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "\n",
    "    return accuracy, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_miou(target,output):\n",
    "\n",
    "\n",
    "    eps=1e-6\n",
    "    #output=output.squeeze(2)\n",
    "    num_classes=output.shape[1]\n",
    "    preds = torch.argmax(output, dim=1)\n",
    "\n",
    "    # Flatten the tensors\n",
    "    preds = preds.view(-1)  # Flatten predictions\n",
    "    target = target.view(-1)  # Flatten target\n",
    "    \n",
    "    # Initialize intersection and union for each class\n",
    "    intersection = torch.zeros(num_classes)\n",
    "    union = torch.zeros(num_classes)\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "\n",
    "        # Create binary masks for the current class\n",
    "        pred_mask = (preds == cls).float()\n",
    "        target_mask = (target == cls).float()\n",
    "       \n",
    "        # Calculate intersection and union\n",
    "        intersection[cls] = (pred_mask * target_mask).sum()\n",
    "        union[cls] = pred_mask.sum() + target_mask.sum() - intersection[cls]\n",
    "        \n",
    "    # Calculate IoU for each class\n",
    "    iou = intersection / (union + eps)  # Add eps to avoid division by zero\n",
    "    \n",
    "    # Calculate mean IoU\n",
    "    mean_iou = iou.mean().item()\n",
    "\n",
    "    return mean_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.375 0.5454545454545454 0.1874999850988388\n",
      "0.5 0.6666666666666666 0.2499999701976776\n",
      "0.375 0.5454545454545454 0.1874999850988388\n",
      "0.4166666666666667 0.5858585858585857 0.2083333134651184\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "output=torch.tensor([[[[0.1,0.1],[0.1,0.3]],[[0.3,0.2],[0.5,0.4]]],[[[0.1,0.1],[0.1,0.1]],[[0.3,0.2],[0.5,0.4]]]])\n",
    "labels_1=torch.tensor([[[1,0],[0,1]],[[0,0],[0,1]]])\n",
    "labels_2=torch.tensor([[[1,0],[1,1]],[[0,0],[0,1]]])\n",
    "labels_3=torch.tensor([[[0,0],[1,1]],[[0,0],[0,1]]])\n",
    "output=output.reshape(2,2,2,2)\n",
    "labels_1=labels_1.reshape(2,2,2)\n",
    "labels_2=labels_2.reshape(2,2,2)\n",
    "labels_3=labels_3.reshape(2,2,2)\n",
    "#x=calculate_miou(labels, output)\n",
    "\n",
    "acc_t=[]\n",
    "miou_t=[]\n",
    "f1_t=[]\n",
    "for i in range(3):\n",
    "    if i==0:\n",
    "        labels=labels_1\n",
    "    elif i==1:\n",
    "        labels=labels_2\n",
    "    elif i==2:\n",
    "        labels=labels_3\n",
    "    acc,f1=compute_metrics(labels,output)\n",
    "    miou=calculate_miou(labels,output)\n",
    "    acc_t.append(acc)\n",
    "    f1_t.append(f1)\n",
    "    miou_t.append(miou)\n",
    "    print(acc,f1,miou)\n",
    "\n",
    "acc=np.mean(acc_t)\n",
    "f1=np.mean(f1_t)\n",
    "miou=np.mean(miou_t)\n",
    "print(acc,f1,miou)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hls2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
